---
title: "Study S3"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
  pdf_document: 
    toc: yes
    toc_depth: 3
    fig_caption: true
header-includes:
  \renewcommand{\contentsname}{Items}
   \usepackage{fvextra}
   \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
---

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE,
	results = "hide"
)
library(dplyr)
library(lmtest)
library(sandwich)
library(systemfit)
library(car)
library(broom)
library(qualtRics)
library(knitr)
library(rmarkdown)
library(tidyverse)
```

```{r include=FALSE}
if ( (!is.null(knitr::current_input()))) {
  if (("pdf_document" ==
                rmarkdown::all_output_formats(knitr::current_input())[1])) {
      stargazer_type <- "latex"
  }
} else {
  stargazer_type <- "text"
}

robust_summary <- function(model) {
    # Calculating robust standard errors
    robust_se <- sqrt(diag(vcovHC(model, type = "HC3")))

    # Getting original model summary
    model_summary <- summary(model)

    # Updating standard errors, t-values, and p-values in the coefficients table
    model_summary$coefficients[, "Std. Error"] <- robust_se
    model_summary$coefficients[, "t value"] <- model_summary$coefficients[, "Estimate"] / robust_se
    model_summary$coefficients[, "Pr(>|t|)"] <- 2 * pt(-abs(model_summary$coefficients[, "t value"]), df = model_summary$df[2], lower.tail = TRUE)

    return(model_summary)
}
robust_confint <- function(model, level = 0.95) {
    # Calculating robust standard errors
    robust_se <- sqrt(diag(vcovHC(model, type = "HC3")))

    # Getting the coefficients
    est <- coef(model)

    # Calculating the critical value for the t-distribution
    alpha <- 1 - level
    t_crit <- qt(1 - alpha / 2, df = df.residual(model))

    # Calculating the confidence intervals
    lower <- est - t_crit * robust_se
    upper <- est + t_crit * robust_se

    # Combining into a matrix
    confint <- cbind(lower, upper)
    rownames(confint) <- names(est)
    colnames(confint) <- c("2.5 %", "97.5 %")

    return(confint)
}
```

\newpage


```{r include=FALSE}
## Pull directly from Qualtrics API
qual_data <- fetch_survey(surveyID='SV_3jZLUQYdzXtaJCu',
                   label = T,
                   convert = F,
                   start_date = "2024-07-05",
                   force_request = T)

```

```{r}
URM <- c(
  "Cherelle Parker", 
  "Eric Adams", 
  "Justin Bibb", 
  "London Breed", 
  "Karen Bass", 
  "Brandon Johnson", 
  "Todd Gloria", 
  "Eric Johnson", 
  "Vi Lyles", 
  "Victoria Woodards", 
  "LaToya Cantrell", 
  "Yadira Ramos-Herbert", 
  "Francis Suarez", 
  "Rex Richardson", 
  "Yemi Mobolade", 
  "Andre Dickens", 
  "Regina Romero", 
  "Quinton Lucas", 
  "Cavalier Johnson",
  "Keith James",
  "Shawyn Patterson-Howard",
  "Tishaura Jones"
  
)


d0 <- qual_data |> 
  filter(!is.na(`choice-7`), !is.na(workerId), Finished==1) |> 
  mutate(
    race_pick = case_when(`choice-7` %in% URM ~ 1,
                           TRUE ~ 0),
         race_feedback = ifelse(cond=="treat", 1, 0),
    majority_pool = case_when(pool == 'Non-URM' ~ 1,
                     TRUE ~ 0),
    gender_code = case_when(gender=="Man" ~ 1, TRUE ~ 0),
    race_code = case_when(race=="White / Caucasian" ~ 1, TRUE ~ 0),
    base_race = rowSums(across(`choice-1`:`choice-6`, ~ . %in% URM))
  ) |> 
  select(race_pick:race_code, gender, race, age, `choice-1`:`choice-7`)


d0_majority_pool <- d0 |> 
  filter(majority_pool==1)

d0_minority_pool <- d0 |> 
  filter(majority_pool==0)

# Write the API-pulled data into a CSV file

write.csv(d0, 'StudyS3.csv', row.names = FALSE, quote = TRUE) 

###########################################################################################
# when reading the csv, use the following command: read.csv('StudyS3.csv', check.names = F)
###########################################################################################
```

\newpage

## Variable Names

\begin{table}[!htbp] \centering 
  \label{tab:variables} 
\begin{tabular}{|l|p{10cm}|} 
\hline 
\textbf{Variable} & \textbf{Description} \\ 
\hline 
\texttt{race\_feedback} & Binary indicator of whether a participant was randomly assigned to race feedback condition. \\
\hline
\texttt{race\_pick} & Binary indicator of whether a participant selected a racial minority mayor for their seventh selection. \\
\hline
\texttt{majority\_pool} & Binary indicator of whether a participant was randomly assigned to white-dominated mayor pool. \\
\hline
\texttt{choice-1 to choice-7} & The selected mayors. \\
\hline
\texttt{gender} & Self-selected gender. \\
\hline
\texttt{race} & Self-selected race. \\
\hline
\texttt{age} & Self-entered age. \\
\hline
\texttt{gender\_code} & Dummy code for gender (male = 1). \\
\hline
\texttt{race\_code} & Dummy code for race (white = 1). \\
\hline
\end{tabular} 
\end{table} 



```{r include=FALSE, results='markup'}
## Excluded participants

cat('Excluded Participants:', nrow(qual_data) - nrow(d0), '\n')

## Gender

gender_percentages <- round(prop.table(table(d0$gender)) * 100, 2)

gender_df <- data.frame(
  Percentage = gender_percentages,
  gender = names(gender_percentages)
)[1:2]

colnames(gender_df) <- c("Percentage", "gender")

print(gender_df)


## Race

race_percentages <- round(prop.table(table(d0$race)) * 100, 2)

race_df <- data.frame(
  Percentage = race_percentages,
  Race = names(race_percentages)
)[1:2]

colnames(race_df) <- c("Percentage", "Race")

print(race_df)

## Age

age_summary <- d0 |> 
  select(age) |> 
  summarize(mean_age = mean(age, na.rm = T), sd_age = sd(age, na.rm = T))

age_summary

```

\newpage

## Primary Analyses

### Race Feedback when Racial Minority Underrepresented in Candidate Set


```{r echo=F, results='markup'}
# racial minority is underrepresented
r_majority <- lm(race_pick ~ race_feedback, data=d0_majority_pool)

# Display the summary with robust standard errors
robust_summary(r_majority)
robust_confint(r_majority)


```

\newpage

### Race Feedback when Racial Minority Overrepresented in Candidate Set


```{r echo=F, results='markup'}
# primary model, no encouragement
r_minority <- lm(race_pick ~ race_feedback, data=d0_minority_pool)

# Display the summary with robust standard errors
robust_summary(r_minority)
robust_confint(r_minority)

```
\newpage

### Race Feedback * Racial Minority Underrepresented



```{r echo=FALSE, results='markup'}
# primary model, no encouragement
r3 <- lm(race_pick ~ race_feedback*majority_pool, data=d0)

# Display the summary with robust standard errors
robust_summary(r3)
robust_confint(r3)

```

\newpage

## Robustness

```{r echo=TRUE, results='markup'}
## robust to demographic controls
### when racial minorities are underrepresented

r3 <- lm(race_pick ~ race_feedback + gender_code + race_code + age, data=d0_majority_pool)

# Display the robust_summary with robust standard errors
robust_summary(r3)
robust_confint(r3)

## logistic regression
# Fit the logistic regression model
r4 <- glm(race_pick ~ race_feedback, family = binomial, data=d0_majority_pool)

# Odds ratio
tidy_r4 <- tidy(r4, exponentiate = TRUE, conf.int = T)
print(tidy_r4)
summary(r4)

## robust to demographic controls
### when racial minorities are overrepresented

r5 <- lm(race_pick ~ race_feedback + gender_code + race_code + age, data=d0_minority_pool)

# Display the robust_summary with robust standard errors
robust_summary(r5)
robust_confint(r5)

## logistic regression
# Fit the logistic regression model
r6 <- glm(race_pick ~ race_feedback, family = binomial, data=d0_majority_pool)

# Odds ratio
tidy_r6 <- tidy(r6, exponentiate = TRUE, conf.int = T)
print(tidy_r6)
summary(r6)


### interaction model

r7 <- lm(race_pick ~ race_feedback*majority_pool + gender_code + race_code + age, data=d0)

# Display the robust_summary with robust standard errors
robust_summary(r7)
robust_confint(r7)

## logistic regression
# Fit the logistic regression model
r8 <- glm(race_pick ~ race_feedback*majority_pool, family = binomial, data=d0)

# Odds ratio
tidy_r8 <- tidy(r8, exponentiate = TRUE, conf.int = T)
print(tidy_r8)
summary(r8)
```



