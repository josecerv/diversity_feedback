---
title: "Study 2B"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
  pdf_document: 
    toc: yes
    toc_depth: 2
    fig_caption: true
header-includes:
  \renewcommand{\contentsname}{Items}
   \usepackage{fvextra}
   \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
---

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE,
	results = "hide"
)
library(dplyr)
library(lmtest)
library(sandwich)
library(systemfit)
library(car)
library(broom)
library(qualtRics)
library(knitr)
library(rmarkdown)
library(tidyverse)
library(psych)
library(mediation)
```

```{r include=FALSE}
if ( (!is.null(knitr::current_input()))) {
  if (("pdf_document" ==
                rmarkdown::all_output_formats(knitr::current_input())[1])) {
      stargazer_type <- "latex"
  }
} else {
  stargazer_type <- "text"
}


robust_summary <- function(model) {
    # Calculating robust standard errors
    robust_se <- sqrt(diag(vcovHC(model, type = "HC3")))

    # Getting original model summary
    model_summary <- summary(model)

    # Updating standard errors, t-values, and p-values in the coefficients table
    model_summary$coefficients[, "Std. Error"] <- robust_se
    model_summary$coefficients[, "t value"] <- model_summary$coefficients[, "Estimate"] / robust_se
    model_summary$coefficients[, "Pr(>|t|)"] <- 2 * pt(-abs(model_summary$coefficients[, "t value"]), df = model_summary$df[2], lower.tail = TRUE)

    return(model_summary)
}
robust_confint <- function(model, level = 0.95) {
    # Calculating robust standard errors
    robust_se <- sqrt(diag(vcovHC(model, type = "HC3")))

    # Getting the coefficients
    est <- coef(model)

    # Calculating the critical value for the t-distribution
    alpha <- 1 - level
    t_crit <- qt(1 - alpha / 2, df = df.residual(model))

    # Calculating the confidence intervals
    lower <- est - t_crit * robust_se
    upper <- est + t_crit * robust_se

    # Combining into a matrix
    confint <- cbind(lower, upper)
    rownames(confint) <- names(est)
    colnames(confint) <- c("2.5 %", "97.5 %")

    return(confint)
}
extract_regression_estimates <- function(model) {
  # Get robust summary
  rob_sum <- robust_summary(model)
  # Get robust confidence intervals
  rob_ci <- robust_confint(model)
  
  # Extract coefficient for the treatment variable (second row)
  estimate <- rob_sum$coefficients[2, "Estimate"] * 100  # Convert to percentage points
  se <- rob_sum$coefficients[2, "Std. Error"] * 100
  ci_lower <- rob_ci[2, 1] * 100
  ci_upper <- rob_ci[2, 2] * 100
  
  return(list(
    estimate = estimate,
    se = se,
    ci_lower = ci_lower,
    ci_upper = ci_upper
  ))
}
```

\newpage

## Read Data

```{r echo=TRUE}
# Set this to TRUE if you have API access, FALSE if using CSV
USE_API <- FALSE

if(USE_API) {
  ## Pull directly from Qualtrics API
  qual_data <- fetch_survey(surveyID='SV_9KBd2ktMonQbXWS',
                     label = T,
                     convert = F,
                     start_date = "2022-10-14",
                     force_request = T)
} else {
  # Read the processed data directly from CSV
  d0 <- read.csv('Study2B.csv', check.names = F)
  num_excluded <- unique(d0$num_excluded_total)
}

# Define the categories
books_list <- c("Agatha Christie", "Alice Walker", "Charles Dickens", "Herman Melville", "Isabel Allende", "Jack London", "John Steinbeck", "Joyce Carol Oates", "Jorge Luis Borges", "JRR Tolkien", "Louisa May Alcott", "Lucy Maud", "Michael Crichton", "Sandra Cisneros", "Toni Morrison")
oldies_list <- c("Agatha Christie", "Charles Dickens", "Emily Bronte", "Ernest Hemingway", "Herman Melville", "Jack London", "Jane Austen", "Jorge Luis Borges", "JRR Tolkien", "Louisa May Alcott", "Lucy Maud", "Nathaniel Hawthorne", "WEB Du Bois")
poets_list <- c("Alice Walker", "Charles Dickens", "Emily Bronte", "George Orwell", "Jack London", "James Baldwin", "Joyce Carol Oates", "Jorge Luis Borges", "Louisa May Alcott", "Lucy Maud", "Sandra Cisneros", "Sylvia Plath", "Toni Morrison")
race_list <- c("Alice Walker", "Gabriel Garcia Marquez", "Isabel Allende", "James Baldwin", "Sandra Cisneros", "Toni Morrison", "WEB Du Bois", "Jorge Luis Borges")

if(USE_API) {
  d0 <- qual_data |> 
    mutate(ec_2 = tolower(ec_2)) |> 
    filter(workerId!="", selection_6 != "", ec_2 %in% c("one one", "\"one one\""), bonus_ctrl2_7 != "" | 
                  bonus_ctrl1_7 != "" | 
                  bonus_trt_7 != "", Finished==1) |> 
    dplyr::select(c(selection_1:last_col()))  |>  
    # Replace NA with an empty string in relevant columns
    mutate(across(starts_with("race"), ~replace_na(., ""), .names = "new_{.col}")) %>%
    # Combine race columns into a single column
    unite("race_combined", starts_with("new_race"), sep = ", ", na.rm = TRUE, remove = TRUE) %>%
    # Clean up the race column
    mutate(race = sapply(strsplit(race_combined, ", "), function(x) {
      cleaned_entries = x[!str_detect(x, "^\\s*$")]
      paste(cleaned_entries, collapse = ", ")
    }))  |> 
    mutate(race_choice = across(c(bonus_ctrl2_7, bonus_ctrl1_7, bonus_trt_7),
                  ~ case_when(. %in% race_list ~ 1,
                              TRUE ~ 0)),
           book_choice = across(c(bonus_ctrl2_7, bonus_ctrl1_7, bonus_trt_7),
                  ~ case_when(. %in% books_list  ~ 1,
                              TRUE ~ 0)),
            oldies_choice = across(c(bonus_ctrl2_7, bonus_ctrl1_7, bonus_trt_7),
                  ~ case_when(. %in% oldies_list ~ 1,
                    TRUE ~ 0)),
            poets_choice = across(c(bonus_ctrl2_7, bonus_ctrl1_7, bonus_trt_7),
                  ~ case_when(. %in% poets_list ~ 1,
                    TRUE ~ 0)),
           race_feedback = case_when(group %in% c("control1", "control2") ~ 0,
                                 TRUE ~ 1)) |> 
    mutate(race_pick = case_when(race_choice$bonus_ctrl2_7==1 | race_choice$bonus_ctrl1_7==1 |  race_choice$bonus_trt_7==1 ~ 1, TRUE ~ 0),
           poets_pick = case_when(poets_choice$bonus_ctrl2_7==1 | poets_choice$bonus_ctrl1_7==1 |  poets_choice$bonus_trt_7==1 ~ 1, TRUE ~ 0),
           oldies_pick = case_when(oldies_choice$bonus_ctrl2_7==1 | oldies_choice$bonus_ctrl1_7==1 |  oldies_choice$bonus_trt_7==1 ~ 1, TRUE ~ 0),
           book_pick = case_when(book_choice$bonus_ctrl2_7==1 | book_choice$bonus_ctrl1_7==1 |  book_choice$bonus_trt_7==1 ~ 1, TRUE ~ 0),
           poets = case_when((group == "control1" & (`count_type-1` == "wrote poetry" | `count_type-2` == "wrote poetry")) | (group=="control2") | (group=="treatment" & (`minority_count_type-1` == "wrote poetry" | `minority_count_type-2` == "wrote poetry" | `minority_count_type-3` == "wrote poetry")) ~ 1, TRUE ~ 0),
           oldies = case_when((group == "control1" & (`count_type-1` == "were born in the 1800s" | `count_type-2` == "were born in the 1800s")) | (group=="control2") | (group=="treatment" & (`minority_count_type-1` == "were born in the 1800s" | `minority_count_type-2` == "were born in the 1800s" | `minority_count_type-3` == "were born in the 1800s")) ~ 1, TRUE ~ 0),
           books = case_when((group == "control1" & (`count_type-1` == "wrote more than 10 books" | `count_type-2` == "wrote more than 10 books")) | (group=="control2") | (group=="treatment" & (`minority_count_type-1` == "wrote more than 10 books" | `minority_count_type-2` == "wrote more than 10 books" | `minority_count_type-3` == "wrote more than 10 books")) ~ 1, TRUE ~ 0),
            gender_code = case_when(gender=="Man" ~ 1, TRUE ~ 0),
            race_code = case_when(str_detect(race, "White / Caucasian") ~ 1, TRUE ~ 0),
           age = as.numeric(age),
           list_two = case_when(group=="control1" ~ 1, group=="control2" ~ 0, TRUE ~ NA_real_)) |> 
    mutate(
      across(c(I1:E3),
             ~ case_when(
               . == "Strongly disagree" ~ 1, . == "Disagree" ~ 2, . == "Somewhat disagree" ~ 3, . == "Neither agree nor disagree" ~ 4, 
               . == "Somewhat agree" ~ 5, . == "Agree" ~ 6, . == "Strongly agree" ~ 7, TRUE ~ NA_integer_))) |> 
    mutate(
      internal1Z = (I1 - mean(I1, na.rm = TRUE)) / sd(I1, na.rm = TRUE),
      internal2Z = (I2 - mean(I2, na.rm = TRUE)) / sd(I2, na.rm = TRUE),
      internal3Z = (I3 - mean(I3, na.rm = TRUE)) / sd(I3, na.rm = TRUE),
      internal4Z = (I4 - mean(I4, na.rm = TRUE)) / sd(I4, na.rm = TRUE),
      internal = (internal1Z + internal2Z + internal3Z + internal4Z) / 4,
      external1Z = (E1 - mean(E1, na.rm = TRUE)) / sd(E1, na.rm = TRUE),
      external2Z = (E2 - mean(E2, na.rm = TRUE)) / sd(E2, na.rm = TRUE),
      external3Z = (E3 - mean(E3, na.rm = TRUE)) / sd(E3, na.rm = TRUE),
      external = (external1Z + external2Z + external3Z) / 3,
      base_race = rowSums(across(selection_1:selection_6, ~ . %in% race_list))
    ) |> 
    dplyr::select(list_two, race_feedback, race_pick:books, base_race, selection_1:selection_6,bonus_ctrl2_7, bonus_ctrl1_7, bonus_trt_7, race, gender, age, gender_code, race_code, internal1Z:external) |> 
    slice(1:1000) #pre-registered sample size 

  # Calculate the number of excluded participants
  num_excluded <- nrow(qual_data) - nrow(d0)

  # Save num_excluded in d0
  d0$num_excluded_total <- num_excluded  # As a column
    
  # Write the API-pulled data into a CSV file
  write.csv(d0, 'Study2B.csv', row.names = FALSE, quote = TRUE)
}

```

\newpage

## Variable Names

\begin{table}[!htbp] \centering 
  \label{tab:variables} 
\begin{tabular}{|l|p{10cm}|} 
\hline 
\textbf{Variable} & \textbf{Description} \\ 
\hline 
\texttt{list\_two} & Binary indicator of whether the control received a list of two attributes (list\_two=1) or not (list\_two=0). \\
\hline
\texttt{race\_feedback} & Binary indicator of whether a participant was randomly assigned to race feedback condition. \\
\hline
\texttt{race\_pick} & Binary indicator of whether a participant selected a racial minority protagonist for their seventh author selection \\
\hline
\texttt{poets\_pick} & Binary indicator of whether a participant selected an author that wrote poetry for their seventh selection. \\
\hline
\texttt{oldies\_pick} & Binary indicator of whether a participant selected an author that was born in the $1800s$ for their seventh selection. \\
\hline
\texttt{book\_pick} & Binary indicator of whether a participant selected an author that wrote more than $10$ books for their seventh selection. \\
\hline
\texttt{base\_race} & Count of the number of racial minority authors selected in the initial six authors. \\
\hline
\texttt{selection\_1 to selection\_6} & The selected authors \\
\hline
\texttt{bonus\_ctrl1\_7, bonus\_ctrl2\_7} & The final selected author for control \\
\hline
\texttt{bonus\_trt\_7} & The final selected author for treatment \\
\hline
\texttt{gender} & Self-selected gender. \\
\hline
\texttt{race} & Self-selected race. \\
\hline
\texttt{age} & Self-entered age. \\
\hline
\texttt{gender\_code} & Dummy code for gender (male = 1). \\
\hline
\texttt{race\_code} & Dummy code for race (white = 1). \\
\hline
\texttt{internal1Z-4Z} & Individual standardized scale items for Internal Motivation to Respond Without Prejudice. \\
\hline
\texttt{external1Z-3Z} & Individual standardized scale items for External Motivation to Respond Without Prejudice. \\
\hline
\texttt{internal} & Aggregated scale items for Internal Motivation to Respond Without Prejudice. \\
\hline
\texttt{external} & Aggregated scale items for External Motivation to Respond Without Prejudice. \\
\hline
\end{tabular} 
\end{table} 

\newpage

## Demographics

```{r results='markup'}
## Excluded participants

cat('Excluded Participants:', num_excluded, '\n')

## Gender

gender_percentages <- round(prop.table(table(d0$gender)) * 100, 2)

gender_df <- data.frame(
  Percentage = gender_percentages,
  gender = names(gender_percentages)
)[1:2]

colnames(gender_df) <- c("Percentage", "gender")

print(gender_df)


## Race

# Separate the combined race entries and unlist
individual_races <- unlist(strsplit(d0$race, ",\\s*"))

# Create a new data frame with these individual race entries
race_data <- data.frame(Race = individual_races)

# Calculate the proportions
race_percentages <- round(prop.table(table(race_data$Race)) * 100, 2)

# Create the final data frame
race_df <- data.frame(
  Percentage = as.numeric(race_percentages),
  Race = names(race_percentages)
)
# Reorder the columns
race_df <- race_df[c("Race", "Percentage")]

# Print the data frame
print(race_df)

## Age

age_summary <- d0 |> 
  dplyr::select(age) |> 
  summarize(mean_age = mean(age, na.rm = T), sd_age = sd(age, na.rm = T))

age_summary

```

\newpage

## Cronbach's Alpha

```{r echo=TRUE, results='markup'}
# Calculating Cronbach's Alpha for the Internal subscale
internal_items <- d0[, c("internal1Z", "internal2Z", "internal3Z", "internal4Z")]
alpha_internal <- alpha(internal_items)

cat("Cronbach's Alpha for Internal Subscale: ", alpha_internal$total$raw_alpha, "\n")

# Calculating Cronbach's Alpha for the External subscale
external_items <- d0[, c("external1Z", "external2Z", "external3Z")]
alpha_external <- alpha(external_items)
cat("Cronbach's Alpha for External Subscale: ", alpha_external$total$raw_alpha, "\n")

```

\newpage

## Pooled Analysis

```{r echo=TRUE, results='markup'}

r0 <- lm(race_pick ~ list_two, data=d0)

# Display the summary with robust standard errors
robust_summary(r0)

```

## Primary Analysis

```{r echo=TRUE, results='markup'}
# primary model
r1 <- lm(race_pick ~ race_feedback, data=d0)
summary(r1)

# Display the summary with robust standard errors
robust_summary(r1)
robust_confint(r1)
```

\newpage

## Robustness

```{r echo=TRUE, results='markup'}

## which feedback was shown with gender, remove constant due to collinearity
r2 <- lm(race_pick ~ race_feedback + oldies_pick + poets_pick + book_pick - 1, data=d0)


# Display the summary with robust standard errors
robust_summary(r2)

## robust to demographic controls

r3 <- lm(race_pick~ race_feedback + gender_code + race_code + age, data=d0)

# robust standard errors
robust_summary(r3)
robust_confint(r3)

## logistic regression
# Fit the logistic regression model
r4 <- glm(race_pick ~ race_feedback, family = binomial, data=d0)
summary(r4)
# Odds ratio
tidy_r4 <- tidy(r4, exponentiate = TRUE, conf.int = T)
print(tidy_r4)
```

## Interaction Analysis

```{r echo=TRUE, results='markup'}
## interaction of base gender
# primary model
r_interaction <- lm(race_pick ~ race_feedback*base_race, data=d0)


# Display the summary with robust standard errors
robust_summary(r_interaction)

```

\newpage

## Secondary Analysis


```{r}
## oldies feedback
r_oldies <- lm(oldies_pick ~ oldies, data=d0)

# Display the robust_summary with robust standard errors
robust_summary(r_oldies)
robust_confint(r_oldies)


## poets feedback
r_poets <- lm(poets_pick ~ poets, data=d0)

# Display the robust_summary with robust standard errors
robust_summary(r_poets)
robust_confint(r_poets)


## books feedback
r_books <- lm(book_pick ~ books, data=d0)


# Display the robust_summary with robust standard errors
robust_summary(r_books)
robust_confint(r_books)

```

```{r include=FALSE}
# Extract estimates for overall plot
race_est <- extract_regression_estimates(r1)
oldies_est <- extract_regression_estimates(r_oldies)
poets_est <- extract_regression_estimates(r_poets)
books_est <- extract_regression_estimates(r_books)

study2B_estimates <- data.frame(
    Study = "STUDY 2B",
    Stimuli = c("race", "oldies", "poets", "books"),
    Estimate = c(race_est$estimate, oldies_est$estimate, poets_est$estimate, books_est$estimate),
    SE = c(race_est$se, oldies_est$se, poets_est$se, books_est$se),
    CI_Lower = c(race_est$ci_lower, oldies_est$ci_lower, poets_est$ci_lower, books_est$ci_lower),
    CI_Upper = c(race_est$ci_upper, oldies_est$ci_upper, poets_est$ci_upper, books_est$ci_upper)
)
getwd()
# Save the estimates to an RDS file
saveRDS(study2B_estimates, file = "../Manuscript_Figures/figure3-estimates/study2B_estimates.rds")

```


\newpage

## Mediation


```{r echo=TRUE, results='markup'}
# Set seed for reproducibility
set.seed(123)

# Define function for Sobel Test
sobel_test <- function(med.fit, out.fit, mediator) {
  med.se <- sqrt(diag(vcovHC(med.fit)))[mediator]
  out.se <- sqrt(diag(vcovHC(out.fit)))[mediator]
  sobel_test_statistic <- coef(out.fit)[mediator] / sqrt(vcovHC(out.fit)[mediator, mediator])
  sobel_p_value <- 2 * (1 - pnorm(abs(sobel_test_statistic)))
  list(statistic = sobel_test_statistic, p_value = sobel_p_value, se = out.se)
}

# -----------------------------
# Internal Motivation Analysis
# -----------------------------

# Direct effect model
dir.fit.internal <- lm(race_pick ~ race_feedback, data=d0)

# Mediator model
med.fit.internal <- lm(internal ~ race_feedback, data = d0)

# Outcome model including mediator
out.fit.internal <- lm(race_pick ~ race_feedback + internal, data = d0)

# Mediation analysis
med.out.internal <- mediate(med.fit.internal, out.fit.internal, boot = TRUE, 
                            treat = "race_feedback", boot.ci.type = "perc", mediator = "internal", sims = 10000)

# Sensitivity analysis
sens.out.internal <- medsens(med.out.internal, rho.by = 0.01, eps=.01, effect.type = "indirect", sims = 10000)

# Sobel test for internal motivation
sobel.internal <- sobel_test(med.fit.internal, out.fit.internal, "internal")

# Print and visualize results for internal motivation
cat("Sobel test for Internal Motivation\n")
print(sobel.internal)
summary(med.out.internal)
plot(sens.out.internal)


# -----------------------------
# External Motivation Analysis
# -----------------------------

# Direct effect model (same as internal, so no need to recompute)
# dir.fit.external <- dir.fit.internal

# Mediator model
med.fit.external <- lm(external ~ race_feedback, data = d0)

# Outcome model including mediator
out.fit.external <- lm(race_pick ~ race_feedback + external, data = d0)

# Mediation analysis
med.out.external <- mediate(med.fit.external, out.fit.external, boot = TRUE, 
                            treat = "race_feedback", boot.ci.type = "perc", mediator = "external", sims = 10000)

# Sensitivity analysis
sens.out.external <- medsens(med.out.external, rho.by = 0.01, eps=.01, effect.type = "indirect", sims = 10000)

# Sobel test for external motivation
sobel.external <- sobel_test(med.fit.external, out.fit.external, "external")

# Print and visualize results for external motivation
cat("Sobel test for External Motivation\n")
print(sobel.external)
summary(med.out.external)
plot(sens.out.external)

# ---------------------------------
# Combined Multiple Mediation Model
# ---------------------------------

# Compute the correlation coefficient and p-value
correlation_result <- cor.test(d0$internal, d0$external)
correlation_coefficient <- correlation_result$estimate
p_value <- correlation_result$p.value

# Print the results
cat("Correlation Between Internal and External: ", correlation_coefficient, "\n")
cat("P-value: ", p_value, "\n")

# Building combined outcome model with both mediators
out.fit.combined <- lm(race_pick ~ race_feedback + internal + external, data = d0)

# Run combined mediation analyses
med.out.combined.internal <- mediate(med.fit.internal, out.fit.combined, boot = TRUE, 
                                     treat = "race_feedback", boot.ci.type = "perc", mediator = "internal", sims = 10000)
med.out.combined.external <- mediate(med.fit.external, out.fit.combined, boot = TRUE, 
                                     treat = "race_feedback", boot.ci.type = "perc", mediator = "external", sims = 10000)

# Summarize and print the results for combined analysis
cat("Combined Multiple Mediation Model Results\n")
summary(med.out.combined.internal)
summary(med.out.combined.external)
```

\newpage

## Figure S3

```{r echo=TRUE}

drace_plot <- d0 |> 
  dplyr::select(race_feedback, race_pick) |> 
  dplyr::group_by(race_feedback) |> 
  dplyr::summarise(
    n = n(),  
    freq = mean(race_pick),  
    sd = sd(race_pick) * 100, 
    se = (sd(race_pick) / sqrt(n())) * 100  
  ) |> 
  mutate(race_feedback = case_when(race_feedback==1 ~ "\"Treatment\"",
                          TRUE ~ "\"Control\"")) |> 
  rename(Condition = race_feedback)

##### poets


r_poets <- lm(poets_pick ~ poets, data=d0)

dpoets_plot <- d0 |> 
  dplyr::select(poets, poets_pick) |> 
  dplyr::group_by(poets) |> 
  dplyr::summarise(
    n = n(),  
    freq = mean(poets_pick),  
    sd = sd(poets_pick) * 100, 
    se = (sd(poets_pick) / sqrt(n())) * 100  
  ) |> 
  mutate(poets = case_when(poets==1 ~ "\"Treatment\"",
                          TRUE ~ "\"Control\"")) |> 
  rename(Condition = poets)


##### books

r_books <- lm(book_pick ~ books, data=d0)

dbooks_plot <- d0 |> 
  dplyr::select(books, book_pick) |> 
  dplyr::group_by(books) |> 
  dplyr::summarise(
    n = n(),  
    freq = mean(book_pick),  
    sd = sd(book_pick) * 100, 
    se = (sd(book_pick) / sqrt(n())) * 100  
  ) |> 
  mutate(books = case_when(books==1 ~ "\"Treatment\"",
                          TRUE ~ "\"Control\"")) |> 
  rename(Condition = books)


#### oldies

r_oldies <- lm(oldies_pick ~ oldies, data=d0)

doldies_plot <- d0 |> 
  dplyr::select(oldies, oldies_pick) |> 
  dplyr::group_by(oldies) |> 
  dplyr::summarise(
    n = n(),  
    freq = mean(oldies_pick),  
    sd = sd(oldies_pick) * 100, 
    se = (sd(oldies_pick) / sqrt(n())) * 100  
  ) |> 
  mutate(oldies = case_when(oldies==1 ~ "\"Treatment\"",
                          TRUE ~ "\"Control\"")) |> 
  rename(Condition = oldies)

## Combine plots

df_combined <- bind_rows(
  dpoets_plot %>% mutate(Category = "\nWrote Poetry"),
  dbooks_plot %>% mutate(Category = "\nWrote > 10 books"),
  doldies_plot %>% mutate(Category = "\nWere Born\nin the 1800s"),
  drace_plot %>% mutate(Category = "\nWere Racial\nMinorities")
, .id = "id") %>% 
  mutate(Category = factor(Category, levels = c('\nWrote Poetry', '\nWrote > 10 books', '\nWere Born\nin the 1800s', '\nWere Racial\nMinorities')))

p_combined <- ggplot(df_combined, aes(x = Condition, y = freq*100, fill = Condition)) +
  geom_bar(stat="identity", width = 0.85, position = position_dodge(width = 0.7)) +
  geom_text(aes(label=paste0(sprintf("%.1f", freq*100),"%")), 
            position=position_dodge(width=0.7), vjust=5, size = 5, color = "white") +
  geom_errorbar(aes(ymin=freq*100-se, ymax=freq*100+se), width = .1, position = position_dodge(width = 0.7)) +
  facet_wrap(~factor(Category, c('\nWrote Poetry', '\nWrote > 10 books', '\nWere Born\nin the 1800s', '\nWere Racial\nMinorities')), nrow = 1, strip.position = "bottom") +
   geom_segment(data = df_combined %>% filter(Condition == "\"Treatment\""), 
                aes(x = 1, xend = 2, y = freq*100 + se + 5, yend = freq*100 + se + 5), 
                inherit.aes = FALSE) +
   geom_text(data = df_combined %>% filter(Category %in% c('\nWrote > 10 books') & Condition == "\"Treatment\""), 
             aes(x = 1.5, xend = 1.5, y = freq*100 + se + 7, yend = freq*100 + se + 7, label = "n.s."), 
             inherit.aes = FALSE, vjust = 0, size = 5) +
    geom_text(data = df_combined %>% filter(Category %in% c('\nWrote Poetry', '\nWere Born\nin the 1800s') & Condition == "\"Treatment\""), 
             aes(x = 1.5, xend = 1.5, y = freq*100 + se + 7, yend = freq*100 + se + 7, label = "+"), 
             inherit.aes = FALSE, vjust = 0, size = 5) +
   geom_text(data = df_combined %>% filter(Category == '\nWere Racial\nMinorities' & Condition == "\"Treatment\""), 
             aes(x = 1.5, xend = 1.5, y = freq*100 + se + 5, yend = freq*100 + se + 5, label = "***"), 
             inherit.aes = FALSE, vjust = 0, size = 5) +
  theme_bw() +
  scale_fill_manual(values = c("#990000", "#011F5B"), labels = c("No feedback provided", "Feedback provided"), "Feedback") +
  scale_y_continuous(labels = function(x) paste0(x,"%"), limits = c(0,95)) +
  scale_x_discrete(labels = c("\"Control\"" = "Not\nShown", "\"Treatment\"" = "Shown")) +
  labs(x = "Feedback on % of authors who...", y = "% of New Authors with the Target Attribute",
       caption = 'Note: Error Bars are SEs', title = "The Effect of Getting Feedback on Your Author Selections") +
  theme(plot.caption = element_text(face = "italic"),
        legend.position = c(0.5, 0.95),
        legend.title = element_blank(),
        legend.direction = "horizontal",
        legend.text = element_text(size = 20),
        legend.key.size = unit(7, 'mm'),
        legend.background = element_rect(fill = "white"),
        panel.grid.minor = element_blank(),
        panel.grid = element_blank(),
        panel.border = element_rect(fill= NA, color = "white"),
        plot.background = element_rect(fill = "white"),
        panel.background = element_rect(fill = "white"),
        axis.title.x = element_text(face="bold", size = 21, vjust = 17),
        plot.title = element_blank(),
        axis.title.y = element_text(size = 20, color = "black"),
        axis.text.x = element_blank(),
        axis.ticks = element_blank(),
        axis.text.y = element_text(size = 20, color = "black"),
        strip.text = element_text(size = 20, color = "black"),
        strip.background = element_rect(colour = "white", fill = "white"))

#p_combined
# Save the plot with Times New Roman font
# ggsave("../Supplemental Studies/Supplemental_Figures/Figure-S2.pdf", plot = p_combined, width = 10, height = 8, units = "in", device = cairo_pdf, family = "Times New Roman")
```

\newpage

## System of Simultaneous Equations

```{r results='markup'}
# poets40
poets.eqn <- list(
  poetseq = as.numeric(poets_pick) ~ poets + books + oldies + race_feedback - 1,
  raceeq = as.numeric(race_pick) ~ poets + books + oldies + race_feedback - 1
)

# Define restriction matrix
restrict_poets <- "poetseq_poets - raceeq_race_feedback = 0"

# Fit the system of equations with the restriction
unrestricted_poets <- systemfit(poets.eqn, data=d0)
#robust_summary(unrestricted_poets)
# books

books.eqn <- list(
  bookseq = as.numeric(book_pick) ~ poets + books + oldies + race_feedback - 1,
  raceeq = as.numeric(race_pick) ~ poets + books + oldies + race_feedback - 1
)

# Define restriction matrix
restrict_books <- "bookseq_books - raceeq_race_feedback = 0"

# Fit the system of equations with the restriction
unrestricted_books <- systemfit(books.eqn, data=d0)

# oldies

oldies.eqn <- list(
  oldieseq = as.numeric(oldies_pick) ~ poets + books + oldies + race_feedback - 1,
  raceeq = as.numeric(race_pick) ~ poets + books + oldies + race_feedback - 1
)

# Define restriction matrix
restrict_oldies <- "oldieseq_oldies - raceeq_race_feedback = 0"

# Fit the system of equations with the restriction
unrestricted_oldies <- systemfit(oldies.eqn, data=d0)


# wald tests
# Run linear hypothesis tests
lh_result_poets = linearHypothesis(unrestricted_poets, restrict_poets)
lh_result_books = linearHypothesis(unrestricted_books, restrict_books)
lh_result_oldies = linearHypothesis(unrestricted_oldies, restrict_oldies)



# Collecting coefficient values and standard errors
poets_coef <- lh_result_poets$F[2]
books_coef <- lh_result_books$F[2]
oldies_coef <- lh_result_oldies$F[2]


# Extracting p-values
p_value_poets = lh_result_poets$`Pr(>F)`[2]
p_value_books = lh_result_books$`Pr(>F)`[2]
p_value_oldies = lh_result_oldies$`Pr(>F)`[2]

# Include p-values in the summary table
data.frame(
  `Test` = c("Race Feedback - poets Feedback", "Race Feedback - books Feedback", "Race Feedback - oldies Feedback"),
  `Wald Coefficient` = c(poets_coef, books_coef, oldies_coef),
  P_Value = c(p_value_poets, p_value_books, p_value_oldies),
  row.names = 1
)

```

